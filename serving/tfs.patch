diff --git a/.bazelrc b/.bazelrc
index eb2a873f..514ad4f0 100644
--- a/.bazelrc
+++ b/.bazelrc
@@ -110,3 +110,6 @@ build --copt=-Wno-macro-redefined # absl vs tsl logging clash
 build --copt=-Wno-sign-compare # int as loop variable
 build --copt=-Wno-deprecated-declarations
 build --copt=-Wno-unused-but-set-variable # due to `ifdefs` in ml_dtypes
+
+build --action_env TF_SYSTEM_LIBS="boringssl"
+build --define=tflite_with_xnnpack=false
diff --git a/WORKSPACE b/WORKSPACE
index d88c9355..d53d6e0e 100644
--- a/WORKSPACE
+++ b/WORKSPACE
@@ -22,10 +22,9 @@ local_repository(
 # 3. Request the new archive to be mirrored on mirror.bazel.build for more
 #    reliable downloads.
 load("//tensorflow_serving:repo.bzl", "tensorflow_http_archive")
-tensorflow_http_archive(
+local_repository(
     name = "org_tensorflow",
-    sha256 = "403916fbcfcbd5657cd891a871debc72433d7a8c56760297a79085e1abc8f18a",
-    git_commit = "6550e4bd80223cdb8be6c3afd1f81e86a4d433c3",
+    path = "SOURCE_ROOT/tensorflow",
 )
 
 # Import all of TensorFlow Serving's external dependencies.
@@ -55,6 +54,7 @@ http_archive(
     sha256 = "84aec9e21cc56fbc7f1335035a71c850d1b9b5cc6ff497306f84cced9a769841",
     strip_prefix = "rules_python-0.23.1",
     url = "https://github.com/bazelbuild/rules_python/releases/download/0.23.1/rules_python-0.23.1.tar.gz",
+    patches = ["//third_party:rules.patch"],
 )
 
 load("@rules_python//python:repositories.bzl", "python_register_toolchains")
diff --git a/tensorflow_serving/servables/tensorflow/saved_model_bundle_factory.cc b/tensorflow_serving/servables/tensorflow/saved_model_bundle_factory.cc
index 516164fc..2c8a1ca8 100644
--- a/tensorflow_serving/servables/tensorflow/saved_model_bundle_factory.cc
+++ b/tensorflow_serving/servables/tensorflow/saved_model_bundle_factory.cc
@@ -68,6 +68,9 @@ Status LoadTfLiteModel(const string& model_dir, SavedModelBundle* bundle,
   model_bytes.resize(size);
   absl::string_view sv;
   TF_RETURN_IF_ERROR(file->Read(0, size, &sv, &model_bytes[0]));
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
 
   std::unique_ptr<TfLiteSession> tflite_session;
   TF_RETURN_IF_ERROR(TfLiteSession::Create(
diff --git a/tensorflow_serving/servables/tensorflow/tflite_interpreter_pool_test.cc b/tensorflow_serving/servables/tensorflow/tflite_interpreter_pool_test.cc
index d13c016c..d54b6380 100644
--- a/tensorflow_serving/servables/tensorflow/tflite_interpreter_pool_test.cc
+++ b/tensorflow_serving/servables/tensorflow/tflite_interpreter_pool_test.cc
@@ -47,6 +47,9 @@ TEST(TfLiteInterpreterPool, CreateTfLiteInterpreterPoolTest) {
   TF_ASSERT_OK(ReadFileToString(Env::Default(),
                                 test_util::TestSrcDirPath(kParseExampleModel),
                                 &model_bytes));
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
   auto model = tflite::FlatBufferModel::BuildFromModel(
       flatbuffers::GetRoot<tflite::Model>(model_bytes.data()));
   int pool_size = 1;
@@ -102,6 +105,9 @@ TEST(TfLiteInterpreterWrapper, TfLiteInterpreterWrapperTest) {
   TF_ASSERT_OK(ReadFileToString(Env::Default(),
                                 test_util::TestSrcDirPath(kParseExampleModel),
                                 &model_bytes));
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
   auto model = tflite::FlatBufferModel::BuildFromModel(
       flatbuffers::GetRoot<tflite::Model>(model_bytes.data()));
   tflite::ops::builtin::BuiltinOpResolver resolver;
diff --git a/tensorflow_serving/servables/tensorflow/tflite_session_main.cc b/tensorflow_serving/servables/tensorflow/tflite_session_main.cc
index d219108b..8f374be9 100644
--- a/tensorflow_serving/servables/tensorflow/tflite_session_main.cc
+++ b/tensorflow_serving/servables/tensorflow/tflite_session_main.cc
@@ -37,6 +37,9 @@ int main(int argc, char** argv) {
   std::string model_bytes;
   auto status =
       ReadFileToString(tensorflow::Env::Default(), filename, &model_bytes);
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
   if (!status.ok()) {
     std::cerr << "ERROR: Failed to read model file: " << filename
               << " with error: " << status << std::endl;
diff --git a/tensorflow_serving/servables/tensorflow/tflite_session_test.cc b/tensorflow_serving/servables/tensorflow/tflite_session_test.cc
index f8c402bd..2c202281 100644
--- a/tensorflow_serving/servables/tensorflow/tflite_session_test.cc
+++ b/tensorflow_serving/servables/tensorflow/tflite_session_test.cc
@@ -86,6 +86,9 @@ TEST(TfLiteSession, BasicTest) {
                                 test_util::TestSrcDirPath(kTestModel),
                                 &model_bytes));
 
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
   ::google::protobuf::Map<string, SignatureDef> signatures;
   std::unique_ptr<TfLiteSession> session;
   tensorflow::SessionOptions options;
@@ -144,6 +147,9 @@ TEST(TfLiteSession, ResizeWithSameNumElementsTest) {
                                 test_util::TestSrcDirPath(kTestModel),
                                 &model_bytes));
 
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
   ::google::protobuf::Map<string, SignatureDef> signatures;
   std::unique_ptr<TfLiteSession> session;
   tensorflow::SessionOptions options;
@@ -197,6 +203,9 @@ TEST(TfLiteSession, ModelFromLegacyConverterWithSigdef) {
                                 test_util::TestSrcDirPath(kTestModelWithSigdef),
                                 &model_bytes));
 
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
   ::google::protobuf::Map<string, SignatureDef> signatures;
   std::unique_ptr<TfLiteSession> session;
   tensorflow::SessionOptions options;
@@ -644,6 +653,9 @@ Status BuildSessionInBatch(std::unique_ptr<TfLiteSession>* sess,
   std::string model_bytes;
   TF_RETURN_IF_ERROR(ReadFileToString(
       Env::Default(), test_util::TestSrcDirPath(model_path), &model_bytes));
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
   auto model = tflite::FlatBufferModel::BuildFromModel(
       flatbuffers::GetRoot<tflite::Model>(model_bytes.data()));
   const int model_batch_size = 5;
@@ -781,6 +793,9 @@ TEST(TfLiteSession, TestSetScheduler) {
   TF_ASSERT_OK(ReadFileToString(Env::Default(),
                                 test_util::TestSrcDirPath(kParseExampleModel),
                                 &model_bytes));
+#if FLATBUFFERS_LITTLEENDIAN == 0
+  tflite::FlatBufferModel::ByteSwapSerializedModel(&model_bytes, false);
+#endif
   auto model = tflite::FlatBufferModel::BuildFromModel(
       flatbuffers::GetRoot<tflite::Model>(model_bytes.data()));
   auto model_signature_def_map = GetTestSignatureDefMap();
